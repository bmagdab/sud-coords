The aim of this work is to expand on already existing research on the coordinate structures in the English language. A coordination is a structure which consists of multiple elements which serve the same function in the sentence and are often connected using a conjunction word. An example of a coordination from the Corpus of Contemporary American English \citep{coca} (COCA, henceforth) is given in (\ref{ex:govLeft}). There, the word \textsl{and} serves as the conjunction, \textsl{this} and \textsl{so many things} as the conjuncts.

\begin{exe}
    \ex
    \label{ex:govLeft} We're opposites \textsl{in} [[this] and [so many things]].
\end{exe}

This coordination is consistent with the observation that in English often the conjuncts on the left of a coordination are shorter than the ones on the right. According to \cite{prz:woz:23} however, the placement of the coordination's governor (the head of the whole structure, the word \textsl{in} in the example above) might have an influence on the way the coordination is structured: if the governor is on the left (as in (\ref{ex:govLeft})) or absent from the coordination altogether (as in (\ref{ex:govNone})), then the left conjunct will be shorter. That is not necessarily the case if the governor is on the right (as in (\ref{ex:govRight})).

\begin{exe}
    \ex\label{ex:govNone} [[She was right], but [he didn't want to say so]].
    \ex\label{ex:govRight} [[Cuban flags unfurled from windows] and [women wept]], Perez \textsl{says}.
\end{exe}

% longer version - explains more thoroughly DLM, but is that needed here?
% The proposed explanation for this comes from the fact that we often try to minimize the distance between connected constituents in a sentence. For example the sentence (3) tells us, that someone reported two events that happened: \textsl{Cuban flags unfurled from windows} and \textsl{women wept}. If that is the case, then those two event descriptions are connected to the word \textsl{says}. Now if we were to place those two descriptions the other way, by the time we got the the word \textsl{says}, we would have trouble recalling what was at the beginning of the sentence. Hence, according to some theories, we tend to shorten the dependencies in the sentences we produce.

% previous version:
%The proposed explanation for this is that Dependency Length Minimization can be observed here, which means that, when creating coordinate structures, we tend to try to minimize the distance between connected constituents. This was found to be the most likely explanation of the results and provided an argument for certain approaches to annotating the dependency structure of a coordination, namely the symmetrical ones. 

The Dependency Length Minimization effect is proposed as an explanation for this, which paired with the results of the research provides an argument for symmetric theories of coordination and against asymmetric ones. There were however some limitations to the research that needed to be addressed. The study was based on the Penn Treebank, a corpus already annotated with constituency structures. The presence of a manually approved syntactic annotation is a huge advantage for research like this, but unfortunately the corpus describes only a narrow fragment of the English language -- it is made up exclusively of the material from the Wall Street Journal and consists of 1.25M tokens, among which there were only 21,825 coordinations to analyse.

% next paragraph of the previous version:
%The research described above is based on the Penn Treebank, a corpus already annotated with constituency structures. Two advantages of such a resource are worth pointing out here: the presence of a manually approved syntactic annotation and the clear information about the exact length of a coordination's conjuncts. Unfortunately, the size of the corpus, as well as its lack of diversity cause the conducted research to describe only a narrow fragment of the English language -- it is made up exclusively of the material from the Wall Street Journal and consists of 1.25M tokens, among which there were only 21,825 coordinations to analyse.

A replication of those results using a different resource has already been attempted and described in an unpublished manuscript by \cite{pbg2023}. The results were similar, but more precise -- they supported not symmetric approaches to coordination in general, but specifically the multi-headed one. The corpus used there was COCA, which consists of over one billion words found in eight different genres ranging from academic to spoken. Unfortunately, it does not have any syntactic annotation that would immediately allow for data extraction and analysis similar to those in the study described above -- it had to be annotated automatically. Because of that, the quality of the data was significantly lower -- only 50.1\% of the coordinations included in the evaluation of data were parsed and extracted correctly. 

Issues with the data could possibly appear either at the parsing stage or at the extraction stage, and using Surface Syntactic Universal Dependencies (SUD) could help with both of those. According to \cite{tuo:prz:lac:21}, for some parsers (particularly the graph-based ones) the SUD annotation scheme might be easier to learn than Universal Dependencies -- the annotation scheme used in the replication study mentioned above. As for the issues at the extraction stage, the SUD scheme has some structural benefits, that can be used to create more accurate heuristics.

% another paragraph of the previous version:
%An example of a bigger and more diverse corpus is the Corpus of Contemporary American English. It consists of over one billion words found in eight different genres ranging from academic to spoken. One downside to this corpus is the absence of any syntactic annotation that would immediately allow for data extraction and analysis similar to those in the study described above. Automatic annotation should be therefore performed, for which the default choice is often the Universal Dependencies scheme \citep{nivre-etal-2020-universal} as seen for example in Stanza \citep{qi2020stanza}, Trankit \citep{nguyen2021trankit}, and COMBO \citep{klimaszewski-wroblewska-2021-combo-state}. However as \cite{prz:woz:23} mentioned, the UD annotation scheme would not be accurate for an analysis of coordination, as it cannot clearly distinguish between shared and private dependencies of a conjunct, thus making it problematic to measure its length -- information vital for this research. The Surface Syntactic Universal Dependencies scheme is an alternative worth considering for three reasons in particular. Firstly, the criteria for choosing dependency heads deployed in the SUD scheme generate syntactic trees without some of the ambiguities present in UD corpora. Secondly, more of those ambiguities can be resolved thanks to the explicitly marked shared dependencies in some coordinate structures. The final advantage of the SUD annotation here is that it can be easier to learn than the UD annotation for some parsers, particularly the graph-based ones \citep{tuo:prz:lac:21}. 

Work reported in this thesis is based on COCA annotated automatically using Stanza \citep{qi2020stanza}, a graph-based dependency parser, in accordance with the SUD annotation scheme. The structure of this thesis is the following: Chapter 2 describes in more detail some of the theoretical aspects mentioned in the current chapter -- this includes previous findings on coordinations in English, the Dependency Length Minimization effect and how it corresponds to different annotation schemes used in dependency treebanks, relevant differences between the UD and SUD annotation schemes and why the syntactic scheme seems to be more appropriate here. Chapter 3 describes how the corpus data was prepared for analysis -- from training the parser to extracting the information about coordinate structures. Chapter 4 presents the analysis of the data, which is discussed in Chapter 5. Finally Chapter 6 covers the limitations of this research. 