\section{Dependency grammars}
% tesniere came up with a somewhat new (panini 600bc) way of creating a syntactic annotation. here are some basic ideas behind it, maybe why it could be useful
The first full-fledged theory of dependency grammar was proposed by \cite{tesniere-orig, tesniere}. One of the key ideas included in his work was that a sentence is not comprised solely of its words, but also of the connections between them -- dependencies. The connections he proposed were directed, therefore one of the two connected words is always a governor (head) and the other is a dependent. Another crucial element of Tesnière's approach was verb centrality -- the verb is the root of every sentence structure in dependency grammar. 

\begin{center}
\begin{exe}
	\ex\label{ex:tesniere}
    \begin{dependency}[theme = simple, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
    \begin{deptext}
        Alfred\& speaks\& slowly.\\
    \end{deptext}
    \depedge{2}{1}{}
    \depedge{2}{3}{}
    \end{dependency}
\end{exe}
\end{center}

% do i have to say it was used by tesniere? how do i say it?
Tesnière as an example used the sentence \textsl{Alfred speaks slowly}, for which a dependency tree is shown in (\ref{ex:tesniere}). It visualises the rules described above -- all of the words in a sentence are connected, those connections are directed and the verb is central to the whole structure. 

Dependency grammars have changed significantly since Tesnière's ideas were published. One example of such changes is the widespread usage of dependency labels, which describe the grammatical function that a word serves -- Tesnière differentiated only between actants and circumstants, which can be understood as obligatory dependencies of a verb, which complete its meaning, and optional dependencies, which are not necessary to complete the meaning of the verb. Different corpora have their own ideas for sets of dependency labels, for instance full annotation for (\ref{ex:tesniere}) could look similarly to (\ref{ex:tesniere today}), with the label \texttt{root} marking the central element of the sentence, \texttt{subj} marking the subject of the sentence and \texttt{mod} marking a modifier of the verb.

\begin{exe}
    \ex
    \label{ex:tesniere today}
    \begin{dependency}[theme = simple, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
    \begin{deptext}
        Alfred\&speaks\&slowly.\\
    \end{deptext}
    \deproot[edge height=5ex]{2}{root}
    \depedge{2}{1}{subj}
    \depedge{2}{3}{mod}
    \end{dependency}
\end{exe} 

Section \ref{sec:dlm} describes some specific phenomena that can be explained using dependency grammars. Section \ref{sec:coord annotations} presents some of the ideas for dependency annotation of coordinate structures that have been used in different corpora and Section \ref{sec:previous} describes the studies that were the basis for the present one. The last two sections of this chapter delve into more detail about two projects concerned with creating consistent dependency annotation schemes -- Universal Dependencies in Section \ref{sec:ud} and Surface-syntactic Universal Dependencies in Section \ref{sec:sud}. 

\section{Dependency length minimization}\label{sec:dlm}
% within this idea of dependencies in language, it was conceived that people while speaking try to minimise the dependencies in their utterances, so that it is easier to parse and understand, what they are trying to say. here are some studies about dlm and how this drive to shorten the dependencies may have affected grammar in some languages (hawkins94?)
% idk if it was within dependency grammars
% CITE TEMPERLEY 2018 SOMEWHERE HERE MAYBE
Familiarity with dependency grammars helps understand the principle of Dependency Length Minimization (henceforth DLM). It states that natural languages prefer shorter dependencies in their sentences. An example from \cite{hp83}, shown in (\ref{ex:dlm janitor}), illustrates this.

%is this really the best example? its very specific, because its about verb-particle constructions, maybe something more general would fit better
\begin{exe}
    \ex\label{ex:dlm janitor}
    \begin{xlist}
    \ex\label{ex:dlm janitor1}
    \begin{dependency}[theme = simple, segmented edge, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
        The\&janitor\&threw\&out\&the\&rickety\&and\&badly\&scratched\&chair.\\
        \end{deptext}
        \depedge{3}{4}{}
    \end{dependency}

    \ex\label{ex:dlm janitor2}
    \begin{dependency}[theme = simple, segmented edge, edge height = 4ex, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
        The\&janitor\&threw\&the\&rickety\&and\&badly\&scratched\&chair\&out.\\
        \end{deptext}
        \depedge{3}{10}{}
    \end{dependency}
    \end{xlist}
\end{exe}

The study has shown that speakers deem sentences similar to (\ref{ex:dlm janitor1}) more acceptable than the ones similar to (\ref{ex:dlm janitor2}).\footnote{In the study, it is actually found that it is not the distance between the verb and the particle that affects the acceptability of sentences like those, but the syntactic complexity of the phrases within that distance. However, according to \cite{wasow2002postverbal}, syntactic complexity as a measure of dependency length correlates with many others proposed, intervening words included.} Proposed explanations for this preference are based on language-processing constraints, which are usually said to be caused by working memory limitations. With longer dependencies, while reading or hearing a sentence, a person has to keep certain words in their working memory for a longer time. The longer the dependency, the harder the retrieval of the needed word from the working memory. Similar effects have been found in other studies, both psycholinguistic ones \citep{KING1991580, GIBSON19981} and those based on corpus research \citep{gildea-temperley-2007-optimizing, gildea-temperley-2010, futrell2020, dyer-2023}. 

% the idea of dlm in grammar and dlm in usage
The DLM effect has been observed both at the level of usage and at the level of grammar. The level of usage is visible in (\ref{ex:dlm janitor}) -- when there are multiple grammatical word orders available, people tend to choose those with shortest dependencies, because it makes the sentence easier to understand. As for DLM in grammar, an example taken from \cite[p.~20]{Hawkins-1994} is in (\ref{ex:hawkins-embed}). 
\begin{exe}
\ex\label{ex:hawkins-embed}
\begin{xlist}
	\ex[*] {Did _{S}[that John failed his exam] surprise Mary?}\label{ex:embedS}
	\ex[] {Did _{NP}[that fact] surprise Mary?}\label{ex:embedNP}
\end{xlist}
\end{exe}
Both of the sentences in (\ref{ex:hawkins-embed}) have a constituent embedded inside of them. In (\ref{ex:embedS}) that constituent is a subordinate clause \textsl{that John failed his exam}, whereas in (\ref{ex:embedNP}) the constituent is a noun phrase \textsl{that fact}. Subordinate clauses are usually longer than noun phrases, therefore dependencies in sentences with embedded clauses can be much longer. According to the DLM hypothesis, this makes the sentence more difficult to process and Hawkins argues that due to this processing difficulty sentences with clauses embedded this way are ungrammatical in English. Since noun phrases are usually shorter, sentences similar to (\ref{ex:embedNP}) are allowed. 

% behagel below, but idk

% One of the earlier formulations of rules similar to DLM was made by \cite{behaghel}. He proposed two laws of word order:

% \begin{itemize}
%     \item[1.] That which belongs together mentally is placed close together.
%     \item[2.] Of two sentence components, the shorter goes before the longer, when possible.
% \end{itemize}

% The first of these could be understood as DLM, while the other is a consequence of DLM in head-initial languages. Looking at how syntactic trees are usually shaped in a language allows for a judgement on the headedness or directionality of said language -- it can be head-initial if most dependencies are directed to right, or head-final if they are mostly directed to the left. English is an example of a head-initial language, therefore the second law proposed by Behaghel holds for English sentences. 

\section{Possible dependency structures of a coordination}\label{sec:coord annotations}
% coordination is a funny structure and there have been many ideas how to annotate them within the dependency approach to syntax. here are some ideas on how to do it, where they come from and maybe some rationale behind them

Different corpora choose different approaches to annotating the dependency structure of coordination. \cite{popel2013coordination} proposed a taxonomy of those, which consists of three families of annotation styles: Prague, Stanford and Moscow. \cite{prz:woz:23} add to those three a London family. All four of those families are described in more detail in the following subsections. Diagrams are used to better illustrate them, where:
\begin{itemize}
    \item $\odot$ is the governor of the coordination;
    \item each $\diamond$ symbolises a token, grouped together with a few others in a rectangle, forming a conjunct;
    \item $\square$ is the conjunction of the coordination.
\end{itemize}

Therefore the sentence \textsl{Mary and her younger sister laughed} using this set of symbols would look like in (\ref{ex:diagram}).

\begin{exe}
    \ex\label{ex:diagram}
\raisebox{-2.3ex}{
    \begin{minipage}{20em}
    \begin{dependency}
        \begin{deptext}
            Mary\&[.5cm]and\&[.5cm]her\&younger\&sister\&[.5cm]laughed\\
            \\
            $\diamond$\&$\square$\&\&$\diamond\diamond\diamond$\&\&$\odot$\\
        \end{deptext}
        \wordgroup{3}{1}{1}{}
        \wordgroup{3}{4}{4}{}
    \end{dependency}
    \end{minipage}
}
\end{exe}

% setting diagram heights and lengths
\newlength{\treeheight}
\newlength{\treewidth}
\settoheight{\treeheight}{
\begin{dependency}[theme = simple]
    \begin{deptext}
        $\diamond$\&$\diamond$\&$\diamond$\&$\diamond$\&$\diamond$\&$\square$\&$\diamond$\&$\diamond$\&$\odot$\\
    \end{deptext}
    \depedge{9}{1}{}
    \depedge{1}{7}{}
    \depedge{7}{6}{}
    \wordgroup{1}{1}{5}{}
    \wordgroup{1}{7}{8}{}
\end{dependency}
}
\settowidth{\treewidth}{
\begin{dependency}[theme = simple]
    \begin{deptext}
        $\odot$\&$\diamond$\&$\diamond$\&$\square$\&$\diamond$\&$\diamond$\&$\diamond$\&$\diamond$\&$\diamond$\&$\odot$\\
    \end{deptext}
    \wordgroup{1}{2}{3}{}
    \wordgroup{1}{5}{9}{}
\end{dependency}
}

This section described the predictions about ordering conjuncts in a coordination that can be made assuming different annotation approaches to coordination and the DLM effect at usage. In all of the diagrams in the current section it is assumed that the head of the conjunct is its first word. This assumption is justified, because the work presented here is based solely on the English language, which is mostly head-initial, therefore the diagrams presented here are more likely to be shaped as they are here than in any other way.

% DLM at grammar is not described here because it not proven to work in coordinations??

\input{theory/structures-bouquet-stanford}
\input{theory/structures-chain-moscow}
\input{theory/structures-multi-headed-london}
\input{theory/structures-conjunction-headed-prague}

\section{Previous studies}\label{sec:previous}
The current study is a replication of \cite{prz:woz:23}, which researched coordinate structures to find out what affected the ordering of conjuncts in an English coordination. The goal was to see whether it is as simple as placing shorter conjuncts on the left or whether the placement of the governor of the coordination has some influence on the ordering. They used the Penn Treebank, which is an annotated corpus of texts from the Wall Street Journal. This relatively small, but high quality dataset allowed them to make an argument for the symmetric styles of annotating coordination. 

The authors first compared the total proportions of coordinations with shorter left conjuncts depending only on the position of the governor, so the probability of finding the shorter conjunct of a coordination on the left depending on whether the governor of the coordination is on the left, on the right or absent. This comparison was not enough to show the influence of the governor, because regardless of the governor position the proportion of shorter left conjuncts was higher, than of shorter right conjuncts. The influence was visible, however, when they took into account how this proportion changes with growing differences in conjunct lengths. The effect of length difference is illustrated in the sentence (\ref{ex:apples}). In (\ref{ex:apples}) the difference in conjunct lenghts is equal to 1 character, which is not enough to affect the working memory. The difference is bigger in sentence (\ref{ex:apples-long}) -- 21 characters -- therefore it is more likely to affect the working memory.

\begin{exe}
    \ex\label{ex:apples}
    \begin{xlist}
    \ex\label{ex:apples-short}
    Bring $\Bigr[$[apples] and [oranges]$\Bigr]$.
    \ex\label{ex:apples-long}
    Bring $\Bigr[$[some apples] and [the oranges your mother gave you]$\Bigr]$.
    \end{xlist}
\end{exe}

Figure \ref{fig:pw23-results} presents how modelled proportions of coordinations with the shorter conjunct placed on the left changed with growing differences in conjunct lengths, here measured in words. When the governor is on the left or when it is absent altogether, the proportions grow with length differences. This means that it is more likely that the shorter conjunct will be on the left in (\ref{ex:apples-long}) than in (\ref{ex:apples-short}). No such tendency was found when the governor is on the right. 

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{inputs/ptb-L.pdf}
    \includegraphics[scale=0.35]{inputs/ptb-0.pdf}
    \includegraphics[scale=0.35]{inputs/ptb-R.pdf}
    \caption{Modelled proportions of coordinations with left conjuncts shorter depending on difference in conjunct lengths from \cite{prz:woz:23}}\label{fig:pw23-results}
\end{figure}

The results obtained in this study are compatible with the predictions of the symmetric annotation styles: the Prague one, assuming DLM working at the level of usage and the London one, assuming also DLM at the level of grammar. An example of DLM in grammar was given in Section \ref{sec:dlm}, but it was not described how it could present itself in coordinations. As was mentioned previously, English is a mostly head-initial language, which in  coordinations means that the governor is usually on the left. When the governor is in fact on the left, the dependencies are shortest when the shorter conjunct is also on the left. There is therefore a grammatical pressure to always put shorter conjuncts on the left, because it should usually lead to shorter dependencies in total. This means that when the coordination has no governor and there is no immediate pressure to order the conjuncts in any way, the shorter conjunct still may be placed on the left, because there is a grammatical pressure to do so.  However as \cite{prz:woz:23} point out, this pressure may be reduced when the length differences between conjuncts are noticably bigger, because then the DLM effect at the level of usage is stronger. 

\cite{pbg2023} have already attempted replicating the results of this research. The aim was to see whether the conclusions drawn in the original study hold up when the data come from a bigger and more diverse corpus. The results are presented in Figure \ref{fig:pbg24-results} -- slightly different from what was found in the original study, but they sharpened the original conlusions. In the bigger dataset the coordinations with the governor on the left and without a governor behave the same -- with growing length differences between conjuncts grows also the proportion of shorter left conjuncts. The difference is that, with the governor on the right, proportion of coordinations with the shorter conjunct on the left decreases with the growing length difference. In the study by \cite{prz:woz:23} it was not clear whether any tendency can be observed when the governor is on the right, therefore this difference was the novel finding of \cite{pbg2023}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.27]{inputs/coca-L.png}
    \includegraphics[scale=0.27]{inputs/coca-0.png}
    \includegraphics[scale=0.27]{inputs/coca-R.png}
    \caption{Modelled proportions of coordinations with left conjuncts shorter depending on difference in conjunct lengths from \cite{pbg2023}}\label{fig:pbg24-results}
\end{figure}

The results shown in (\ref{fig:pbg24-results}) point to only one of the annotation styles, namely the London one. Within this style, dependencies are minimised when the shorter conjunct is placed closer to the governor, assuming there is one. Therefore with the governor on the left, the shorter conjunct should also be placed on the left (and the chances of that happening grow with the growing length differences, as shown in the left plot in Figure \ref{fig:pbg24-results}) and with the governor on the right, the shorter conjunct should also be placed on the right (and the chances of that happening grow with the growing length differences, as shown in the right plot in Figure \ref{fig:pbg24-results}). If the coordination has no governor, neither placement should be preferred, unless DLM at the level of grammar is taken into account -- then the shorter conjunct should be preferred on the left, since that usually helps minimise the dependencies. This is again compatible with the data, as shown in the middle plot in Figure \ref{fig:pbg24-results}.

\cite{prz:woz:23} conducted their study on a relatively small, but manually annotated corpus. \cite{pbg2023} replicated that study on a larger, but automatically annotated corpus. This automatic annotation resulted in a poor quality of data -- after evaluating the coordinations extracted for analysis, they found only 50.1\% of their sample to be correctly extracted. This study attempts the replication again, with the same larger corpus but aiming to improve the quality of the automatic annotation by using a different dependency annotation scheme -- Surface-syntactic Universal Dependencies instead of Universal Dependencies. The following sections describe those two projects and present the reasoning behind choosing one of the schemes over the other.

\section{Universal Dependencies}\label{sec:ud}
% theres a project that tries to maybe sort of unify all those ideas for dependency annotation? they want it to be universal, heres how they decided to do it and heres other things about it that will be relevant later (criterion for choosing heads). its been perceived as pretty universal, its used a lot, everywhere almost. there are also enhanced universal depencies, they should be mentioned somewhere although they are not very related to what is described here

% why it was created
As seen in Section \ref{sec:coord annotations}, there are many ideas on the dependency structure of coordination. Not only coordinations, but whole sentences can have different structures depending on the chosen approach to dependency annotation. One of those approaches is presented in this section.

Universal Dependencies (UD, henceforth) is a project focused on formulating guidelines for creating dependency annotation, that would suit as many languages as possible, while maintaining the possibility to represent phenomena specific to any given language. The guidelines give instructions about word segmentation, part-of-speech tagging, assigning morphological features and creating an appropriate dependency tree for a sentence. 

% criteria for choosing dependency heads
Here, the most relevant part of the project are the rules for creating a dependency tree. In the first version of UD \citep{ud1}, three of them were specified: 
\begin{enumerate}
    \item dependency relations appear between content words,
    \item function words are attached to the content words which they describe,
    \item punctuation marks are attached to the head of the phrase or clause in which they appear.
\end{enumerate}
Content words can otherwise be called ``lexical'' or ``semantic'' centres, which means their main purpose is to carry meaning in the sentence, whereas function words serve mostly a syntactic purpose. The difference between the two is visible in sentence (\ref{ex:ud eng tree}), where the word \textsl{participate} carries the meaning, therefore it is the content word and the root of the sentence. The word \textsl{will} is a function word and is attached to the content word.

\begin{adjustwidth}{-40pt}{-40pt}
\vspace{2ex}
\begin{tabular}{l r}
\begin{minipage}[t][12ex][b]{40ex}
\begin{exe}
    \ex\label{ex:ud eng tree}
    \begin{dependency}[baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
            Ivan\&will\&participate\&in the show\&.\\
        \end{deptext}
        \deproot{3}{root}
        \depedge{3}{1}{nsubj}
        \depedge{3}{2}{aux}
        \depedge{3}{4}{nmod}
        \depedge{3}{5}{punct}
    \end{dependency}
\end{exe}
\end{minipage}
&
\hspace{20pt}
\begin{minipage}[t][12ex][b]{40ex}
\begin{exe}
    \ex\label{ex:ud fr tree}
    \begin{dependency}[baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
            Ivan\&participera\&au spectacle\&.\\
        \end{deptext}
        \deproot{2}{root}
        \depedge{2}{1}{nsubj}
        \depedge{2}{3}{nmod}
        \depedge{2}{4}{punct}
    \end{dependency}
\end{exe}
\end{minipage}
\end{tabular}
\vspace{2ex}
\end{adjustwidth}

The reasoning behind setting those criteria is that it increases the chance of finding similar tree structures in different languages, for example when comparing sentences between English and French, which is morphologically richer. (\ref{ex:ud fr tree}) is a tree for the French translation of the sentence in (\ref{ex:ud eng tree}). Even though the French sentence does not have an auxiliary word to mark the future tense, the structures of those sentences are almost identical.

\section{Surface-syntactic Universal Dependencies}\label{sec:sud}
% there was another idea for universal dependency annotation scheme, they want to be universal too, but in a different way, more syntactic but only on the surface. thats why they called themselves surface syntactic universal dependencies. they maybe slightly disagreed with some decisions made in UD so they made their own version. heres how they differ in ways that important for me
Surface-syntactic Universal Dependencies (SUD, henceforth) is another example of a project aiming to create a set of universal guidelines for dependency annotation. \cite{gerdes-etal-2018-sud} describe it as ``near-isomorphic to UD'' and propose a set of conversion rules between the schemes. Most of the SUD annotation guidelines are the same as in UD, the most prominent difference is the change in choosing dependency heads, from content words to function words. This section covers the relevant differences between the schemes and how those are beneficial for research described in this work.

\subsection{Criteria for choosing heads of dependencies}\label{sec:sud criteria}
The UD dependency trees have heads of their dependencies chosen based on the distinction between content words and function words, whereas in the SUD dependency trees heads of dependencies are chosen based on the distributional criteria. \cite{gerdes-etal-2018-sud} say that ``the surface syntactic head determines the distribution of the unit'', so the head of a dependency behaves in sentences similarly to the way the whole unit does, the unit meaning the head and the dependant with all of its dependencies, if there are any. The authors also describe how to test which word is the head of the dependency: in different sentences that word can be replaced by the unit and \textsl{vice versa}. The example sentence the authors use to explain this is \textsl{The little boy talked to Mary}. There is a dependency between words \textsl{little} and \textsl{boy}, and sentences in (\ref{ex:distribution boy}) and (\ref{ex:distribution little}) show why the head of this dependency is the word \textsl{boy}. In (\ref{ex:distribution boy}a) the word \textsl{boy} can be replaced by the unit \textsl{little boy}, as shown in (\ref{ex:distribution boy}b), and the sentence is still grammatical. 

\begin{exe}
    \ex
    \label{ex:distribution boy}
    \begin{xlist}
        \ex[] {I saw a \textbf{boy}.}
        \ex[] {I saw a \textbf{little boy}.}
    \end{xlist}
\end{exe}

Similar replacement cannot be done with the word \textsl{little}. Trying to replace that word in (\ref{ex:distribution little}a) with the whole unit results in an ungrammatical sentence in (\ref{ex:distribution little}b). Sentences (\ref{ex:distribution little}c--d) show that replacement in the other way is not possible either, therefore the word \textsl{little} cannot be the head of this dependency.

\begin{exe}
    \ex
    \label{ex:distribution little}
	\begin{xlist}
    		\ex[] {The boy was \textbf{little}.}
    		\ex[*] {The boy was \textbf{little boy}.}
    		\ex[] {I found the \textbf{little boy}.}
    		\ex[*] {I found the \textbf{little}.}
    \end{xlist}
\end{exe}

It is not always possible to test both of the words within a dependency, but in such cases showing that one of the words does not commute with the whole unit is enough to decide it is not the head, therefore the other one must be. As shown in \cite{gerdes-etal-2018-sud}, that is exactly the case with the words \textsl{to Mary} -- it is impossible to see how the word \textsl{to} behaves on its own, since it needs a noun or a verb. However, the sentences in (\ref{ex:distribution Mary}) show that \textsl{Mary} does not have the same distribution as those two words together -- \textsl{Mary} in (\ref{ex:distribution Mary}a) cannot be replaced by \textsl{to Mary}, as (\ref{ex:distribution Mary}b) shows, and \textsl{to Mary} in (\ref{ex:distribution Mary}c)cannot be replaced by \textsl{Mary}, as (\ref{ex:distribution Mary}d) shows. This is enough to choose the word \textsl{to} as the head of this dependency.

\begin{exe}
    \ex
    \label{ex:distribution Mary}
    \begin{xlist}
    		\ex[] {I saw \textbf{Mary}.}
    		\ex[*] {I saw \textbf{to Mary}.}
    		\ex[] {I talked \textbf{to Mary}.}
    		\ex[*] {I talked \textbf{Mary}.}
    \end{xlist}
\end{exe}

% this difference between schemes is important because it affects extracting the conjunct text in coordinations
% pw23 say that UD is bad for this, SUD is too, but its slightly better, exactly because of the difference described above
% explanation why this difference matters

Because of this difference between UD and SUD in how dependency heads are chosen, the SUD trees reflect more of the syntax of a sentence than the UD trees. This affects which words are found to be inluded in a coordination and consquently what are the length differences between conjuncts, which is an integral part of this work. 

As \cite{prz:woz:23} mention, the UD scheme is not ideal for coordination analysis, as it is not clear which dependencies are shared by the conjuncts and which are private. This is illustrated by the sentences in (\ref{ex:drink-and-drive}) and (\ref{ex:rapidly-expand}).

\begin{adjustwidth}{-40pt}{-40pt}
    \vspace{4ex}
    \begin{tabular}{lr}
    \begin{minipage}[t][12ex][b]{40ex}
    \begin{exe}
    \ex\label{ex:drink-and-drive}
    \begin{dependency}[baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
            Never\& drink\& and\& drive\& .\\
        \end{deptext}
        \deproot{2}{root}
        \depedge{2}{1}{advmod}
        \depedge{2}{4}{conj}
        \depedge{4}{3}{cc}
        \depedge{2}{5}{punct}
    \end{dependency}
    \end{exe}
    \end{minipage}
    &
    \begin{minipage}[t][12ex][b]{40ex}
    \begin{exe}
        \ex\label{ex:rapidly-expand}
        \begin{dependency}[baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
            \begin{deptext}
                 Rapidly\& expanded\& and\& blew\& up\&.\\
            \end{deptext} 
            \depedge{2}{1}{advmod} 
            \depedge{2}{6}{punct}
            \deproot{2}{root} 
            \depedge[edge height=2ex]{4}{3}{cc} 
            \depedge{2}{4}{conj}  
            \depedge[edge height=4ex]{4}{5}{compound:prt}
        \end{dependency}
    \end{exe}
    \end{minipage}
    \end{tabular}
\end{adjustwidth}

In (\ref{ex:drink-and-drive}) the coordinated words are \textsl{drink} and \textsl{drive}, the word \textsl{never} is attached to the first conjunct and even though English speakers reading this sentence know that it applies to the whole coordination, it is not obvious from the structure of the sentence. The structure in (\ref{ex:rapidly-expand}) is similar, but this time the word \textsl{rapidly} applies only to the first conjunct. In both of those sentences knowledge of the real world is required to accurately determine whether the dependency is shared by the whole coordination (as in (\ref{ex:drink-and-drive})) or private to the first conjunct (as in (\ref{ex:rapidly-expand})). Because of this ambiguity, it is difficult to construct accurate heuristics for determining the extent of each conjunct in a coordination. This issue appears in both UD and SUD, however the following examples show that some of the ambiguities present in UD can be resolved in SUD.

% why is that important for me -- give an example of a sentence with a coordination where one of the conjuncts has an auxiliary dependency, which would be troubling to decipher automatically using UD, but not SUD

\cite{pbg2023} describe the heuristics they used for finding the extent of the left conjunct in a coordination in the following way:

\begin{xlist}
    \ex\label{h:right} All dependents directly to the right of the conjunct head were considered private to that conjunct.

    \ex\label{h:compound} Similarly for compound dependents to the left.

    \ex\label{h:left} If a dependency to the left of the head had any other label, it was checked whether any other conjuncts had a dependency with the same label.
    \begin{xlist}
        \ex\label{h:left-priv} If so, these dependencies were considered private to the particular conjuncts.

        \ex\label{h:left-shared} If only the first conjunct had a given dependency type, it was treated as shared by all conjuncts.
    \end{xlist}
\end{xlist}

Let us use an example to consider how those heuristics can be applied and where they fail -- sentence \textsl{This magma often does not reach the surface but cools at depth} (with a tree shown in (\ref{ex:UD magma})) has a coordination with conjuncts \textsl{does not reach the surface} and \textsl{cools at depth}. The \texttt{conj} dependency connects the words \textsl{reach} and \textsl{cools}, so the word \textsl{reach} is the head of the left conjunct. It has a dependency directly on the right, which is always included in the conjunct (based on the Heuristic \ref{h:right}), therefore so far the text of the left conjunct is \textsl{reach the surface}. The head also has some dependencies on the left: one labelled \texttt{aux}, one labelled \texttt{nsubj} and two labelled \texttt{advmod}. According to the Heuristic \ref{h:left-shared}, all of those have to be shared by the whole coordination, meaning that they cannot be included in the left conjunct. Since those are all of the dependencies the head has, the text of the left conjunct is \textsl{reach the surface}, which is incorrect. 

\begin{adjustwidth}{-20pt}{20pt}
\begin{exe}
    \ex\label{ex:UD magma}
    \begin{dependency}[hide label, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
            This\& magma\& often\& does\& not\& reach\& the\& surface\& but\& cools\& at\& depth\&.\footnotemark\\
        \end{deptext}
    \depedge{2}{1}{det} 
    \depedge[show label]{6}{2}{nsubj} 
    \depedge[show label]{6}{3}{advmod} 
    \depedge[show label]{6}{4}{aux} 
    \depedge[show label]{6}{5}{advmod} 
    \deproot[show label, edge height=3cm]{6}{root} 
    \depedge{8}{7}{det} 
    \depedge{6}{8}{obj} 
    \depedge[show label]{10}{9}{cc} 
    \depedge[show label, edge height=2cm, theme=night]{6}{10}{conj} 
    \depedge{12}{11}{case} 
    \depedge[show label]{10}{12}{obl} 
    \wordgroup{1}{6}{8}{}
    \wordgroup{1}{10}{12}{}
\end{dependency}
\end{exe}
\footnotetext{Sentence \texttt{w01031015} from the \texttt{UD\_English-PUD} corpus \citep{pud}.}
\end{adjustwidth}

\begin{adjustwidth}{-20pt}{20pt}
\begin{exe}
\ex\label{ex:UD ballet}
\begin{dependency}[hide label, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
    \begin{deptext}
        Ballet\& shoes\& should\& be\& snug,\& but\& not\& so\& tight\& they\& cut\& off\& blood\& flow\&.\footnotemark\\
    \end{deptext}
    \deproot[show label, edge height=3cm]{5}{root}
    \depedge[show label]{5}{2}{nsubj}
    \depedge{2}{1}{compound}
    \depedge[show label]{5}{3}{aux}
    \depedge[show label]{5}{4}{cop}
    \depedge[show label, theme=night]{5}{9}{conj}
    \depedge[show label]{9}{6}{cc}
    \depedge[show label]{9}{7}{advmod}
    \depedge[show label]{9}{8}{advmod}
    \depedge[show label]{9}{11}{advcl}
    \depedge{11}{10}{nsubj}
    \depedge{11}{12}{compound:prt}
    \depedge[edge height=1.5cm]{11}{14}{obj}
    \depedge{14}{13}{compound}
    \wordgroup{1}{5}{5}{}
    \wordgroup{1}{7}{14}{}
\end{dependency}
\end{exe}
\footnotetext{Sentence \texttt{GUM\_whow\_ballet-14} from the \texttt{UD\_English-GUM} corpus \citep{Zeldes2017}.}
\end{adjustwidth}

Modifying the heuristics, so that they fit this example, for instance by saying that \texttt{aux} dependencies should always be included in the left conjunct, would on the other hand mean that sentences such as in (\ref{ex:UD ballet}) would have incorrect extracted coordinations. In this example the correct coordinate structure has conjuncts \textsl{snug} and \textsl{not so tight they cut off blood flow}, but if the algorithm included the \texttt{aux} dependency in the first conjunct (as would be required in (\ref{ex:UD magma})), the result would be conjuncts \textsl{should be snug} and \textsl{not so tight they cut off blood flow}.

This however is not an issue when using the SUD scheme. As shown in (\ref{ex:SUD magma}), the words \textsl{does not} cannot be dependencies of the whole coordination, because the word \textsl{does} is the head of the left conjunct and the word \textsl{not} is one of its dependencies on the right and thus is always included in the conjunct. Changing the annotation scheme to SUD does not affect the sentence in (\ref{ex:UD ballet}) -- the word \textsl{snug} has to be the whole left conjunct, because it also does not have any dependencies in this annotation scheme.

\begin{adjustwidth}{-20pt}{20pt}
\begin{exe}
\ex\label{ex:SUD magma}
\begin{dependency}[hide label, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
	\begin{deptext}
		This\& magma\& often\& does\& not\& reach\& the\& surface\& but\& cools\& at\& depth\&.\footnotemark\\
	\end{deptext} 
	\depedge{2}{1}{det} 
	\depedge[show label]{4}{2}{subj} 
	\depedge[show label]{4}{3}{mod} 
	\deproot[show label, edge height=2cm]{4}{root} 
	\depedge{4}{5}{mod} 
	\depedge{4}{6}{comp:aux} 
	\depedge{8}{7}{det} 
	\depedge{6}{8}{comp:obj} 
	\depedge[show label]{10}{9}{cc} 
	\depedge[show label, edge height=1.5cm, theme=night]{4}{10}{conj} 
	\depedge[show label]{10}{11}{udep} 
	\depedge{11}{12}{comp:obj} 
    \wordgroup{1}{4}{8}{}
    \wordgroup{1}{10}{12}{}
\end{dependency}
\end{exe}
\footnotetext{Sentence \texttt{w01031015} from the \texttt{SUD\_English-PUD}.}
\end{adjustwidth}

\begin{adjustwidth}{-20pt}{20pt}
\begin{exe}
    \ex\label{ex:SUD ballet}
    \begin{dependency}[hide label, baseline=-\the\dimexpr\fontdimen22\textfont2\relax]
        \begin{deptext}
            Ballet\& shoes\& should\& be\& snug,\& but\& not\& so\& tight\& they\& cut\& off\& blood\& flow\&.\footnotemark\\
        \end{deptext}
    \deproot{3}{root}
    \depedge{3}{2}{subj}
    \depedge{2}{1}{compound}
    \depedge{3}{4}{comp:aux}
    \depedge{4}{5}{comp:pred}
    \depedge[show label, theme=night]{5}{9}{conj}
    \depedge[show label]{9}{6}{cc}
    \depedge[show label]{9}{7}{mod}
    \depedge[show label]{9}{8}{mod}
    \depedge[show label]{9}{11}{mod}
    \depedge{11}{10}{subj}
    \depedge{11}{12}{compound@prt}
    \depedge{11}{14}{comp:obj}
    \depedge{14}{13}{compound}
    \wordgroup{1}{5}{5}{}
    \wordgroup{1}{7}{14}{}
    \end{dependency}
\end{exe}
\footnotetext{Sentence \texttt{GUM\_whow\_ballet-14} from the \texttt{SUD\_English-GUM} corpus.}
\end{adjustwidth}

Therefore, the focus on syntax in SUD makes it a better fit for coordination analysis.

\subsection{Explicit information about shared dependencies}\label{sec:shared-deps}
Besides the structural advantages that SUD has over UD when it comes to analysing coordination, there is one additional feature that is added in SUD treebanks that helps find the extent of conjuncts. 

While UD corpora are often created specifially for the purpose of participating in the UD project or converted with manual corrections from different dependency annotations, the SUD corpora are mostly converted automatically from UD. There are a few French treebanks, as well as treebanks for Beja, Zaar, Chinese and Naija, that are natively made for SUD, but all others are converted from UD using rule-based graph transformation grammars. 

UD uses the Bouquet approach to annotating coordination, while SUD uses the Chain one. This means that in the conversion process, some information about the privacy status of a dependency of the coordination can be lost. This is visible in the coordination presented in the sentence \textsl{I just sat in there for like an hour and a half straight and studied}.\footnote{Sentence \texttt{GUM\_vlog\_studying-27} from the GUM corpus \citep{Zeldes2017}.} As the UD annotation in (\ref{ex:UD 1,5h straight}) shows, the word \textsl{straight} is shared by the whole structure. This is not structurally visible in the SUD version in (\ref{ex:SUD 1,5h straight}), where the \texttt{mod} dependency for the word \textsl{straight} is attached to the last conjunct. 

\begin{adjustwidth}{-50pt}{-50pt}
\vspace{2ex}
\centering
\begin{tabular}{lr}
\begin{minipage}[t][9ex][b]{8cm}
\begin{exe}
    \ex\label{ex:UD 1,5h straight}
    \begin{dependency}[baseline=2.8ex]
        \begin{deptext}
            an\&hour\&and\&a\&half\&straight\\
            \&\&\&\&\&\footnotesize\textsf{upos=ADV}\\
            \&\&\&\&\&\footnotesize\textsf{lemma=straight}\\
            \&\&\&\&\&\footnotesize\textsf{Degree=Pos}\\
        \end{deptext}
        \depedge[edge height=6ex]{2}{5}{conj}
        \depedge[edge height=3ex]{5}{3}{cc}
        \depedge[edge height=8ex]{2}{6}{advmod}
    \end{dependency}
\end{exe}
\end{minipage}
&
\begin{minipage}[t][8.8ex][b]{8cm}
\begin{exe}
    \ex\label{ex:SUD 1,5h straight}
    \begin{dependency}[baseline=3.8ex]
        \begin{deptext}
            an\&hour\&and\&a\&half\&straight\\
            \&\&\&\&\&\footnotesize\textsf{upos=ADV}\\
            \&\&\&\&\&\footnotesize\textsf{lemma=straight}\\
            \&\&\&\&\&\footnotesize\textsf{Degree=Pos}\\
            \&\&\&\&\&\footnotesize\textsf{Shared=Yes}\\
        \end{deptext}
        \depedge[edge height=6ex]{2}{5}{conj}
        \depedge[edge height=3ex]{5}{3}{cc}
        \depedge{5}{6}{mod}
    \end{dependency}
\end{exe}
\end{minipage}
\end{tabular}
\end{adjustwidth}

So as not to lose this information while converting the annotation scheme, feature \textsf{Shared=Yes} is added. Similarly, in coordinations where a dependent is attached to the right conjunct in the UD scheme (therefore private to the right conjuct), during the conversion to SUD the feature \textsf{Shared=No} is added.

\subsection{Learnability of dependency schemes}\label{sec:learnability}
% in pbg23 they tried to use ud but failed (50.1%)
The current study is another replication of \cite{prz:woz:23}. As was pointed out in Chapter \ref{ch:introduction}, \cite{pbg2023} have conducted a similar analysis on the COCA corpus annotated automatically in the UD scheme. After evaluating the automatically annotated data they found only 50.1\% of the coordinations in the evaluation sample to be correctly extracted from the corpus. Reasons for such an outcome can be twofold: the issues lie either within the parsing accuracy or within the script for extracting coordinations from dependency trees. 

Issues within the script have been addressed to some extent in Section \ref{sec:sud criteria} -- heuristics for finding conjunct extents are easier to develop within a function-word focused annotation scheme. As for the parsing performance, there are studies showing that the UD scheme is harder to parse. \cite{rehbein-etal-2017-universal} show that choosing content words rather than function words for dependency heads increases arc direction entropy (a measure describing how consistent dependency directions in a given treebank are), which then lowers parsing accuracy. In another study, \cite{kohita-etal-2017-multilingual} converted UD trees into ones with function heads, rather than content heads. They then used the converted trees for training parsers and parsed 19 treebanks using both UD and converted models. After parsing, the results from the converted models were converted back to UD and for most of the languages (11 out of 19) those results had better scores. 

The criterion for choosing dependency heads may not be the only structural advantage that SUD has over UD in terms of parsing. As \cite{gerdes-etal-2018-sud} demonstrate, the Chain approach to annotating coordination, that is used in SUD, minimises the dependency lengths compared to the Bouquet approach used in UD. This may be beneficial for parsing accuracy, as parsers tend to perform better when working with shorter dependencies \citep{nilsson-etal-2006-graph, eisner-smith-2005-parsing}. 
% could add here about shorter dependencies in SUD than UD in general, citing typometrics.elizia.net, but idk how to do that
% As can be observed in [typometrics], SUD has overall shorter dependencies than UD, therefore whole SUD structures might prove to be easier to parse than UD ones and possibly yield better results at the evaluation stage. 

In the studies cited above the comparison was between UD and a scheme that differed from UD only in some particular aspect, not a new, comprehensive scheme. \cite{tuo:prz:lac:21}, however, compared UD to SUD, which matters because, as they say, ``any realistic annotation schema which employs a more ‘syntactic’ approach to headedness than UD will also differ from UD in the repertoire and distribution of dependency labels, and will also take into account the intrinsic linguistic interaction between various constructions''. They trained five parsers, two of which were transition-based and three graph-based, using 21 corpora representing 18 languages. While transition-based parsers seemed to perform similarly on both annotation schemes, the graph-based ones preferred SUD. As for attachment scores for the English corpus tested in this experiment (GUM), all of the parsers scored higher with the SUD annotation. The parser utilised in the current study, Stanza, is graph-based and the language of the texts it annotates is English, therefore SUD might be the better choice for the annotation scheme for this data. 

%\section{Summary}
% to summarise, you can try to see the syntactic structure of a sentence in different ways, i.e. constituency or dependency (any others?). dependency ones are important here, because i use those approaches in the current study. i use a parser to add syntactic annotation to a large corpus. the parser im using is said to work better with SUD rather than UD, so thats the scheme im choosing. the next chapters describe the exact ways in which this syntactic annotation is added and how i later extract the information that i need.